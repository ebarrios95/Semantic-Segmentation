{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebarrios95/Semantic-Segmentation/blob/main/Sem_Segmentation_attempt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y-rbTuCq0wV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras import layers\n",
        "from types import MethodType\n",
        "import six\n",
        "import os \n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTHzb5X2r9g3"
      },
      "outputs": [],
      "source": [
        "IMAGE_ORDERING_CHANNELS_LAST = \"channels_last\"\n",
        "IMAGE_ORDERING_CHANNELS_FIRST = \"channels_first\"\n",
        "\n",
        "# Default IMAGE_ORDERING = channels_last\n",
        "IMAGE_ORDERING = IMAGE_ORDERING_CHANNELS_LAST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTtauf6XtVXs"
      },
      "outputs": [],
      "source": [
        "if IMAGE_ORDERING == 'channels_first':\n",
        "    pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
        "                     \"releases/download/v0.1/\" \\\n",
        "                     \"vgg16_weights_th_dim_ordering_th_kernels_notop.h5\"\n",
        "elif IMAGE_ORDERING == 'channels_last':\n",
        "    pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
        "                     \"releases/download/v0.1/\" \\\n",
        "                     \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jpd5PsxfqrGJ"
      },
      "outputs": [],
      "source": [
        "def get_segmentation_model(input, output):\n",
        "\n",
        "    img_input = input\n",
        "    o = output\n",
        "\n",
        "    o_shape = Model(img_input, o).output_shape\n",
        "    i_shape = Model(img_input, o).input_shape\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        output_height = o_shape[2]\n",
        "        output_width = o_shape[3]\n",
        "        input_height = i_shape[2]\n",
        "        input_width = i_shape[3]\n",
        "        n_classes = o_shape[1]\n",
        "        o = (Reshape((-1, output_height*output_width)))(o)\n",
        "        o = (Permute((2, 1)))(o)\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        output_height = o_shape[1]\n",
        "        output_width = o_shape[2]\n",
        "        input_height = i_shape[1]\n",
        "        input_width = i_shape[2]\n",
        "        n_classes = o_shape[3]\n",
        "        o = (Reshape((output_height*output_width, -1)))(o)\n",
        "\n",
        "    o = (Activation('softmax'))(o)\n",
        "    model = Model(img_input, o)\n",
        "    model.output_width = output_width\n",
        "    model.output_height = output_height\n",
        "    model.n_classes = n_classes\n",
        "    model.input_height = input_height\n",
        "    model.input_width = input_width\n",
        "    model.model_name = \"\"\n",
        "\n",
        "    model.train = MethodType(train, model)\n",
        "    model.predict_segmentation = MethodType(predict, model)\n",
        "    model.predict_multiple = MethodType(predict_multiple, model)\n",
        "    model.evaluate_segmentation = MethodType(evaluate, model)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki6eqBMNq73P"
      },
      "source": [
        "<h1>Define the Model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWV-S2vgq_Yq"
      },
      "outputs": [],
      "source": [
        "if IMAGE_ORDERING == 'channels_first':\n",
        "    MERGE_AXIS = 1\n",
        "elif IMAGE_ORDERING == 'channels_last':\n",
        "    MERGE_AXIS = -1\n",
        "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
        "          input_width=608, channels=3):\n",
        "\n",
        "    img_input, levels = encoder(\n",
        "        input_height=input_height, input_width=input_width, channels=channels)\n",
        "    [f1, f2, f3, f4, f5] = levels\n",
        "\n",
        "    o = f4\n",
        "\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(512, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (concatenate([o, f3], axis=MERGE_AXIS))\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(256, (3, 3), padding='valid', activation='relu' , data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (concatenate([o, f2], axis=MERGE_AXIS))\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(128, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
        "\n",
        "    if l1_skip_conn:\n",
        "        o = (concatenate([o, f1], axis=MERGE_AXIS))\n",
        "\n",
        "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
        "    o = (Conv2D(64, (3, 3), padding='valid', activation='relu', data_format=IMAGE_ORDERING, name=\"seg_feats\"))(o)\n",
        "    o = (BatchNormalization())(o)\n",
        "\n",
        "    o = Conv2D(n_classes, (3, 3), padding='same',\n",
        "               data_format=IMAGE_ORDERING)(o)\n",
        "\n",
        "    model = get_segmentation_model(img_input, o)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKNjQnZrryKA"
      },
      "outputs": [],
      "source": [
        "def get_vgg_encoder(input_height=224,  input_width=224, pretrained='imagenet', channels=3):\n",
        "\n",
        "    assert input_height % 32 == 0\n",
        "    assert input_width % 32 == 0\n",
        "\n",
        "    if IMAGE_ORDERING == 'channels_first':\n",
        "        img_input = Input(shape=(channels, input_height, input_width))\n",
        "    elif IMAGE_ORDERING == 'channels_last':\n",
        "        img_input = Input(shape=(input_height, input_width, channels))\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               name='block1_conv1', data_format=IMAGE_ORDERING)(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f1 = x\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "               name='block2_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f2 = x\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "               name='block3_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
        "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f3 = x\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block4_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f4 = x\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block5_conv1', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
        "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool',\n",
        "                     data_format=IMAGE_ORDERING)(x)\n",
        "    f5 = x\n",
        "\n",
        "    if pretrained == 'imagenet':\n",
        "        VGG_Weights_path = tf.keras.utils.get_file(\n",
        "            pretrained_url.split(\"/\")[-1], pretrained_url)\n",
        "        Model(img_input, x).load_weights(VGG_Weights_path, by_name=True, skip_mismatch=True)\n",
        "\n",
        "    return img_input, [f1, f2, f3, f4, f5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Eg-BBq5rAtL"
      },
      "outputs": [],
      "source": [
        "def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3, channels=3):\n",
        "\n",
        "    model = _unet(n_classes, get_vgg_encoder,\n",
        "                  input_height=input_height, input_width=input_width, channels=channels)\n",
        "    model.model_name = \"vgg_unet\"\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smIARttOuX1l"
      },
      "outputs": [],
      "source": [
        "def train(model,\n",
        "          train_images,\n",
        "          train_annotations,\n",
        "          input_height=None,\n",
        "          input_width=None,\n",
        "          n_classes=None,\n",
        "          verify_dataset=True,\n",
        "          checkpoints_path=None,\n",
        "          epochs=5,\n",
        "          batch_size=2,\n",
        "          validate=False,\n",
        "          val_images=None,\n",
        "          val_annotations=None,\n",
        "          val_batch_size=2,\n",
        "          auto_resume_checkpoint=False,\n",
        "          load_weights=None,\n",
        "          steps_per_epoch=512,\n",
        "          val_steps_per_epoch=512,\n",
        "          gen_use_multiprocessing=False,\n",
        "          ignore_zero_class=False,\n",
        "          optimizer_name='adam',\n",
        "          do_augment=False,\n",
        "          augmentation_name=\"aug_all\",\n",
        "          callbacks=None,\n",
        "          custom_augmentation=None,\n",
        "          other_inputs_paths=None,\n",
        "          preprocessing=None,\n",
        "          read_image_type=1  # cv2.IMREAD_COLOR = 1 (rgb),\n",
        "                             # cv2.IMREAD_GRAYSCALE = 0,\n",
        "                             # cv2.IMREAD_UNCHANGED = -1 (4 channels like RGBA)\n",
        "         ):\n",
        "    #from .models.all_models import model_from_name\n",
        "    # check if user gives model name instead of the model object\n",
        "    if isinstance(model, six.string_types):\n",
        "        # create the model from the name\n",
        "        assert (n_classes is not None), \"Please provide the n_classes\"\n",
        "        if (input_height is not None) and (input_width is not None):\n",
        "            model = model_from_name[model](\n",
        "                n_classes, input_height=input_height, input_width=input_width)\n",
        "        else:\n",
        "            model = model_from_name[model](n_classes)\n",
        "\n",
        "    n_classes = model.n_classes\n",
        "    input_height = model.input_height\n",
        "    input_width = model.input_width\n",
        "    output_height = model.output_height\n",
        "    output_width = model.output_width\n",
        "\n",
        "    if validate:\n",
        "        assert val_images is not None\n",
        "        assert val_annotations is not None\n",
        "\n",
        "    if optimizer_name is not None:\n",
        "\n",
        "        if ignore_zero_class:\n",
        "            loss_k = masked_categorical_crossentropy\n",
        "        else:\n",
        "            loss_k = 'categorical_crossentropy'\n",
        "\n",
        "        model.compile(loss=loss_k,\n",
        "                      optimizer=optimizer_name,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "    if checkpoints_path is not None:\n",
        "        config_file = checkpoints_path + \"_config.json\"\n",
        "        dir_name = os.path.dirname(config_file)\n",
        "\n",
        "        if ( not os.path.exists(dir_name) )  and len( dir_name ) > 0 :\n",
        "            os.makedirs(dir_name)\n",
        "\n",
        "        with open(config_file, \"w\") as f:\n",
        "            json.dump({\n",
        "                \"model_class\": model.model_name,\n",
        "                \"n_classes\": n_classes,\n",
        "                \"input_height\": input_height,\n",
        "                \"input_width\": input_width,\n",
        "                \"output_height\": output_height,\n",
        "                \"output_width\": output_width\n",
        "            }, f)\n",
        "\n",
        "    if load_weights is not None and len(load_weights) > 0:\n",
        "        print(\"Loading weights from \", load_weights)\n",
        "        model.load_weights(load_weights)\n",
        "\n",
        "    initial_epoch = 0\n",
        "\n",
        "    if auto_resume_checkpoint and (checkpoints_path is not None):\n",
        "        latest_checkpoint = find_latest_checkpoint(checkpoints_path)\n",
        "        if latest_checkpoint is not None:\n",
        "            print(\"Loading the weights from latest checkpoint \",\n",
        "                  latest_checkpoint)\n",
        "            model.load_weights(latest_checkpoint)\n",
        "\n",
        "            initial_epoch = int(latest_checkpoint.split('.')[-1])\n",
        "\n",
        "    if verify_dataset:\n",
        "        print(\"Verifying training dataset\")\n",
        "        verified = verify_segmentation_dataset(train_images,\n",
        "                                               train_annotations,\n",
        "                                               n_classes)\n",
        "        assert verified\n",
        "        if validate:\n",
        "            print(\"Verifying validation dataset\")\n",
        "            verified = verify_segmentation_dataset(val_images,\n",
        "                                                   val_annotations,\n",
        "                                                   n_classes)\n",
        "            assert verified\n",
        "\n",
        "    train_gen = image_segmentation_generator(\n",
        "        train_images, train_annotations,  batch_size,  n_classes,\n",
        "        input_height, input_width, output_height, output_width,\n",
        "        do_augment=do_augment, augmentation_name=augmentation_name,\n",
        "        custom_augmentation=custom_augmentation, other_inputs_paths=other_inputs_paths,\n",
        "        preprocessing=preprocessing, read_image_type=read_image_type)\n",
        "\n",
        "    if validate:\n",
        "        val_gen = image_segmentation_generator(\n",
        "            val_images, val_annotations,  val_batch_size,\n",
        "            n_classes, input_height, input_width, output_height, output_width,\n",
        "            other_inputs_paths=other_inputs_paths,\n",
        "            preprocessing=preprocessing, read_image_type=read_image_type)\n",
        "\n",
        "    if callbacks is None and (not checkpoints_path is  None) :\n",
        "        default_callback = ModelCheckpoint(\n",
        "                filepath=checkpoints_path + \".{epoch:05d}\",\n",
        "                save_weights_only=True,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "        if sys.version_info[0] < 3: # for pyhton 2 \n",
        "            default_callback = CheckpointsCallback(checkpoints_path)\n",
        "\n",
        "        callbacks = [\n",
        "            default_callback\n",
        "        ]\n",
        "\n",
        "    if callbacks is None:\n",
        "        callbacks = []\n",
        "\n",
        "    if not validate:\n",
        "        model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
        "                  epochs=epochs, callbacks=callbacks, initial_epoch=initial_epoch)\n",
        "    else:\n",
        "        model.fit(train_gen,\n",
        "                  steps_per_epoch=steps_per_epoch,\n",
        "                  validation_data=val_gen,\n",
        "                  validation_steps=val_steps_per_epoch,\n",
        "                  epochs=epochs, callbacks=callbacks,\n",
        "                  use_multiprocessing=gen_use_multiprocessing, initial_epoch=initial_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBacWhqrutci"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class_colors = [(random.randint(0, 255), random.randint(\n",
        "    0, 255), random.randint(0, 255)) for _ in range(5000)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vy7FF7GsufRT"
      },
      "outputs": [],
      "source": [
        "def predict(model=None, inp=None, out_fname=None,\n",
        "            checkpoints_path=None, overlay_img=False,\n",
        "            class_names=None, show_legends=False, colors=class_colors,\n",
        "            prediction_width=None, prediction_height=None,\n",
        "            read_image_type=1):\n",
        "\n",
        "    if model is None and (checkpoints_path is not None):\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    assert (inp is not None)\n",
        "    assert ((type(inp) is np.ndarray) or isinstance(inp, six.string_types)),\\\n",
        "        \"Input should be the CV image or the input file name\"\n",
        "\n",
        "    if isinstance(inp, six.string_types):\n",
        "        inp = cv2.imread(inp, read_image_type)\n",
        "\n",
        "    assert (len(inp.shape) == 3 or len(inp.shape) == 1 or len(inp.shape) == 4), \"Image should be h,w,3 \"\n",
        "\n",
        "    output_width = model.output_width\n",
        "    output_height = model.output_height\n",
        "    input_width = model.input_width\n",
        "    input_height = model.input_height\n",
        "    n_classes = model.n_classes\n",
        "\n",
        "    x = get_image_array(inp, input_width, input_height,\n",
        "                        ordering=IMAGE_ORDERING)\n",
        "    pr = model.predict(np.array([x]))[0]\n",
        "    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n",
        "\n",
        "    seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n",
        "                                     colors=colors, overlay_img=overlay_img,\n",
        "                                     show_legends=show_legends,\n",
        "                                     class_names=class_names,\n",
        "                                     prediction_width=prediction_width,\n",
        "                                     prediction_height=prediction_height)\n",
        "\n",
        "    if out_fname is not None:\n",
        "        cv2.imwrite(out_fname, seg_img)\n",
        "\n",
        "    return pr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL2mJ8Duu72Z"
      },
      "outputs": [],
      "source": [
        "def predict_multiple(model=None, inps=None, inp_dir=None, out_dir=None,\n",
        "                     checkpoints_path=None, overlay_img=False,\n",
        "                     class_names=None, show_legends=False, colors=class_colors,\n",
        "                     prediction_width=None, prediction_height=None, read_image_type=1):\n",
        "\n",
        "    if model is None and (checkpoints_path is not None):\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    if inps is None and (inp_dir is not None):\n",
        "        inps = glob.glob(os.path.join(inp_dir, \"*.jpg\")) + glob.glob(\n",
        "            os.path.join(inp_dir, \"*.png\")) + \\\n",
        "            glob.glob(os.path.join(inp_dir, \"*.jpeg\"))\n",
        "        inps = sorted(inps)\n",
        "\n",
        "    assert type(inps) is list\n",
        "\n",
        "    all_prs = []\n",
        "\n",
        "    if not out_dir is None:\n",
        "        if not os.path.exists(out_dir):\n",
        "            os.makedirs(out_dir)\n",
        "\n",
        "\n",
        "    for i, inp in enumerate(tqdm(inps)):\n",
        "        if out_dir is None:\n",
        "            out_fname = None\n",
        "        else:\n",
        "            if isinstance(inp, six.string_types):\n",
        "                out_fname = os.path.join(out_dir, os.path.basename(inp))\n",
        "            else:\n",
        "                out_fname = os.path.join(out_dir, str(i) + \".jpg\")\n",
        "\n",
        "        pr = predict(model, inp, out_fname,\n",
        "                     overlay_img=overlay_img, class_names=class_names,\n",
        "                     show_legends=show_legends, colors=colors,\n",
        "                     prediction_width=prediction_width,\n",
        "                     prediction_height=prediction_height, read_image_type=read_image_type)\n",
        "\n",
        "        all_prs.append(pr)\n",
        "\n",
        "    return all_prs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qlH3henvCXl"
      },
      "outputs": [],
      "source": [
        "def evaluate(model=None, inp_images=None, annotations=None,\n",
        "             inp_images_dir=None, annotations_dir=None, checkpoints_path=None, read_image_type=1):\n",
        "\n",
        "    if model is None:\n",
        "        assert (checkpoints_path is not None),\\\n",
        "                \"Please provide the model or the checkpoints_path\"\n",
        "        model = model_from_checkpoint_path(checkpoints_path)\n",
        "\n",
        "    if inp_images is None:\n",
        "        assert (inp_images_dir is not None),\\\n",
        "                \"Please provide inp_images or inp_images_dir\"\n",
        "        assert (annotations_dir is not None),\\\n",
        "            \"Please provide inp_images or inp_images_dir\"\n",
        "\n",
        "        paths = get_pairs_from_paths(inp_images_dir, annotations_dir)\n",
        "        paths = list(zip(*paths))\n",
        "        inp_images = list(paths[0])\n",
        "        annotations = list(paths[1])\n",
        "\n",
        "    assert type(inp_images) is list\n",
        "    assert type(annotations) is list\n",
        "\n",
        "    tp = np.zeros(model.n_classes)\n",
        "    fp = np.zeros(model.n_classes)\n",
        "    fn = np.zeros(model.n_classes)\n",
        "    n_pixels = np.zeros(model.n_classes)\n",
        "\n",
        "    for inp, ann in tqdm(zip(inp_images, annotations)):\n",
        "        pr = predict(model, inp, read_image_type=read_image_type)\n",
        "        gt = get_segmentation_array(ann, model.n_classes,\n",
        "                                    model.output_width, model.output_height,\n",
        "                                    no_reshape=True, read_image_type=read_image_type)\n",
        "        gt = gt.argmax(-1)\n",
        "        pr = pr.flatten()\n",
        "        gt = gt.flatten()\n",
        "\n",
        "        for cl_i in range(model.n_classes):\n",
        "\n",
        "            tp[cl_i] += np.sum((pr == cl_i) * (gt == cl_i))\n",
        "            fp[cl_i] += np.sum((pr == cl_i) * ((gt != cl_i)))\n",
        "            fn[cl_i] += np.sum((pr != cl_i) * ((gt == cl_i)))\n",
        "            n_pixels[cl_i] += np.sum(gt == cl_i)\n",
        "\n",
        "    cl_wise_score = tp / (tp + fp + fn + 0.000000000001)\n",
        "    n_pixels_norm = n_pixels / np.sum(n_pixels)\n",
        "    frequency_weighted_IU = np.sum(cl_wise_score*n_pixels_norm)\n",
        "    mean_IU = np.mean(cl_wise_score)\n",
        "\n",
        "    return {\n",
        "        \"frequency_weighted_IU\": frequency_weighted_IU,\n",
        "        \"mean_IU\": mean_IU,\n",
        "        \"class_wise_IU\": cl_wise_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZaJFHyNwWKr"
      },
      "outputs": [],
      "source": [
        "def unet(n_classes, input_height=416, input_width=608, encoder_level=3, channels=3):\n",
        "\n",
        "    model = _unet(n_classes, vanilla_encoder,\n",
        "                  input_height=input_height, input_width=input_width, channels=channels)\n",
        "    model.model_name = \"unet\"\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyEeg3_Zxymr"
      },
      "outputs": [],
      "source": [
        "def verify_segmentation_dataset(images_path, segs_path,\n",
        "                                n_classes, show_all_errors=False):\n",
        "    try:\n",
        "        img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
        "        if not len(img_seg_pairs):\n",
        "            print(\"Couldn't load any data from images_path: \"\n",
        "                  \"{0} and segmentations path: {1}\"\n",
        "                  .format(images_path, segs_path))\n",
        "            return False\n",
        "\n",
        "        return_value = True\n",
        "        for im_fn, seg_fn in tqdm(img_seg_pairs):\n",
        "            img = cv2.imread(im_fn)\n",
        "            seg = cv2.imread(seg_fn)\n",
        "            # Check dimensions match\n",
        "            if not img.shape == seg.shape:\n",
        "                return_value = False\n",
        "                print(\"The size of image {0} and its segmentation {1} \"\n",
        "                      \"doesn't match (possibly the files are corrupt).\"\n",
        "                      .format(im_fn, seg_fn))\n",
        "                if not show_all_errors:\n",
        "                    break\n",
        "            else:\n",
        "                max_pixel_value = np.max(seg[:, :, 0])\n",
        "                if max_pixel_value >= n_classes:\n",
        "                    return_value = False\n",
        "                    print(\"The pixel values of the segmentation image {0} \"\n",
        "                          \"violating range [0, {1}]. \"\n",
        "                          \"Found maximum pixel value {2}\"\n",
        "                          .format(seg_fn, str(n_classes - 1), max_pixel_value))\n",
        "                    if not show_all_errors:\n",
        "                        break\n",
        "        if return_value:\n",
        "            print(\"Dataset verified! \")\n",
        "        else:\n",
        "            print(\"Dataset not verified!\")\n",
        "        return return_value\n",
        "    except DataLoaderError as e:\n",
        "        print(\"Found error during data loading\\n{0}\".format(str(e)))\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_kEuzNFyQOu"
      },
      "outputs": [],
      "source": [
        "def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False, other_inputs_paths=None):\n",
        "    \"\"\" Find all the images from the images_path directory and\n",
        "        the segmentation images from the segs_path directory\n",
        "        while checking integrity of data \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    image_files = []\n",
        "    segmentation_files = {}\n",
        "\n",
        "    for dir_entry in os.listdir(images_path):\n",
        "        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n",
        "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
        "            file_name, file_extension = os.path.splitext(dir_entry)\n",
        "            image_files.append((file_name, file_extension,\n",
        "                                os.path.join(images_path, dir_entry)))\n",
        "\n",
        "    if other_inputs_paths is not None:\n",
        "        other_inputs_files = []\n",
        "\n",
        "        for i, other_inputs_path in enumerate(other_inputs_paths):\n",
        "            temp = []\n",
        "\n",
        "            for y, dir_entry in enumerate(os.listdir(other_inputs_path)):\n",
        "                if os.path.isfile(os.path.join(other_inputs_path, dir_entry)) and \\\n",
        "                        os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
        "                    file_name, file_extension = os.path.splitext(dir_entry)\n",
        "\n",
        "                    temp.append((file_name, file_extension,\n",
        "                                 os.path.join(other_inputs_path, dir_entry)))\n",
        "\n",
        "            other_inputs_files.append(temp)\n",
        "\n",
        "    for dir_entry in os.listdir(segs_path):\n",
        "        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n",
        "           os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n",
        "            file_name, file_extension = os.path.splitext(dir_entry)\n",
        "            full_dir_entry = os.path.join(segs_path, dir_entry)\n",
        "            if file_name in segmentation_files:\n",
        "                raise DataLoaderError(\"Segmentation file with filename {0}\"\n",
        "                                      \" already exists and is ambiguous to\"\n",
        "                                      \" resolve with path {1}.\"\n",
        "                                      \" Please remove or rename the latter.\"\n",
        "                                      .format(file_name, full_dir_entry))\n",
        "\n",
        "            segmentation_files[file_name] = (file_extension, full_dir_entry)\n",
        "\n",
        "    return_value = []\n",
        "    # Match the images and segmentations\n",
        "    for image_file, _, image_full_path in image_files:\n",
        "        if image_file in segmentation_files:\n",
        "            if other_inputs_paths is not None:\n",
        "                other_inputs = []\n",
        "                for file_paths in other_inputs_files:\n",
        "                    success = False\n",
        "\n",
        "                    for (other_file, _, other_full_path) in file_paths:\n",
        "                        if image_file == other_file:\n",
        "                            other_inputs.append(other_full_path)\n",
        "                            success = True\n",
        "                            break\n",
        "\n",
        "                    if not success:\n",
        "                        raise ValueError(\"There was no matching other input to\", image_file, \"in directory\")\n",
        "\n",
        "                return_value.append((image_full_path,\n",
        "                                     segmentation_files[image_file][1], other_inputs))\n",
        "            else:\n",
        "                return_value.append((image_full_path,\n",
        "                                     segmentation_files[image_file][1]))\n",
        "        elif ignore_non_matching:\n",
        "            continue\n",
        "        else:\n",
        "            # Error out\n",
        "            raise DataLoaderError(\"No corresponding segmentation \"\n",
        "                                  \"found for image {0}.\"\n",
        "                                  .format(image_full_path))\n",
        "\n",
        "    return return_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8zlxZONy5pK"
      },
      "outputs": [],
      "source": [
        "def image_segmentation_generator(images_path, segs_path, batch_size,\n",
        "                                 n_classes, input_height, input_width,\n",
        "                                 output_height, output_width,\n",
        "                                 do_augment=False,\n",
        "                                 augmentation_name=\"aug_all\",\n",
        "                                 custom_augmentation=None,\n",
        "                                 other_inputs_paths=None, preprocessing=None,\n",
        "                                 read_image_type=cv2.IMREAD_COLOR , ignore_segs=False ):\n",
        "    \n",
        "\n",
        "    if not ignore_segs:\n",
        "        img_seg_pairs = get_pairs_from_paths(images_path, segs_path, other_inputs_paths=other_inputs_paths)\n",
        "        random.shuffle(img_seg_pairs)\n",
        "        zipped = itertools.cycle(img_seg_pairs)\n",
        "    else:\n",
        "        img_list = get_image_list_from_path( images_path )\n",
        "        random.shuffle( img_list )\n",
        "        img_list_gen = itertools.cycle( img_list )\n",
        "\n",
        "\n",
        "    while True:\n",
        "        X = []\n",
        "        Y = []\n",
        "        for _ in range(batch_size):\n",
        "            if other_inputs_paths is None:\n",
        "\n",
        "                if ignore_segs:\n",
        "                    im = next( img_list_gen )\n",
        "                    seg = None \n",
        "                else:\n",
        "                    im, seg = next(zipped)\n",
        "                    seg = cv2.imread(seg, 1)\n",
        "\n",
        "                im = cv2.imread(im, read_image_type)\n",
        "                \n",
        "\n",
        "                if do_augment:\n",
        "\n",
        "                    assert ignore_segs == False , \"Not supported yet\"\n",
        "\n",
        "                    if custom_augmentation is None:\n",
        "                        im, seg[:, :, 0] = augment_seg(im, seg[:, :, 0],\n",
        "                                                       augmentation_name)\n",
        "                    else:\n",
        "                        im, seg[:, :, 0] = custom_augment_seg(im, seg[:, :, 0],\n",
        "                                                              custom_augmentation)\n",
        "\n",
        "                if preprocessing is not None:\n",
        "                    im = preprocessing(im)\n",
        "\n",
        "                X.append(get_image_array(im, input_width,\n",
        "                                         input_height, ordering=IMAGE_ORDERING))\n",
        "            else:\n",
        "\n",
        "                assert ignore_segs == False , \"Not supported yet\"\n",
        "\n",
        "                im, seg, others = next(zipped)\n",
        "\n",
        "                im = cv2.imread(im, read_image_type)\n",
        "                seg = cv2.imread(seg, 1)\n",
        "\n",
        "                oth = []\n",
        "                for f in others:\n",
        "                    oth.append(cv2.imread(f, read_image_type))\n",
        "\n",
        "                if do_augment:\n",
        "                    if custom_augmentation is None:\n",
        "                        ims, seg[:, :, 0] = augment_seg(im, seg[:, :, 0],\n",
        "                                                        augmentation_name, other_imgs=oth)\n",
        "                    else:\n",
        "                        ims, seg[:, :, 0] = custom_augment_seg(im, seg[:, :, 0],\n",
        "                                                               custom_augmentation, other_imgs=oth)\n",
        "                else:\n",
        "                    ims = [im]\n",
        "                    ims.extend(oth)\n",
        "\n",
        "                oth = []\n",
        "                for i, image in enumerate(ims):\n",
        "                    oth_im = get_image_array(image, input_width,\n",
        "                                             input_height, ordering=IMAGE_ORDERING)\n",
        "\n",
        "                    if preprocessing is not None:\n",
        "                        if isinstance(preprocessing, Sequence):\n",
        "                            oth_im = preprocessing[i](oth_im)\n",
        "                        else:\n",
        "                            oth_im = preprocessing(oth_im)\n",
        "\n",
        "                    oth.append(oth_im)\n",
        "\n",
        "                X.append(oth)\n",
        "\n",
        "            if not ignore_segs:\n",
        "                Y.append(get_segmentation_array(\n",
        "                    seg, n_classes, output_width, output_height))\n",
        "\n",
        "        if ignore_segs:\n",
        "            yield np.array(X)\n",
        "        else:\n",
        "            yield np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lag7zaoVzWIo"
      },
      "outputs": [],
      "source": [
        "def get_image_array(image_input,\n",
        "                    width, height,\n",
        "                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n",
        "    \"\"\" Load image array from input \"\"\"\n",
        "\n",
        "    if type(image_input) is np.ndarray:\n",
        "        # It is already an array, use it as it is\n",
        "        img = image_input\n",
        "    elif isinstance(image_input, six.string_types):\n",
        "        if not os.path.isfile(image_input):\n",
        "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
        "                                  .format(image_input))\n",
        "        img = cv2.imread(image_input, read_image_type)\n",
        "    else:\n",
        "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
        "                              .format(str(type(image_input))))\n",
        "\n",
        "    if imgNorm == \"sub_and_divide\":\n",
        "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
        "    elif imgNorm == \"sub_mean\":\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        img = img.astype(np.float32)\n",
        "        img = np.atleast_3d(img)\n",
        "\n",
        "        means = [103.939, 116.779, 123.68]\n",
        "\n",
        "        for i in range(min(img.shape[2], len(means))):\n",
        "            img[:, :, i] -= means[i]\n",
        "\n",
        "        img = img[:, :, ::-1]\n",
        "    elif imgNorm == \"divide\":\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        img = img.astype(np.float32)\n",
        "        img = img/255.0\n",
        "\n",
        "    if ordering == 'channels_first':\n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vqv4d6Fzbj3"
      },
      "outputs": [],
      "source": [
        "def get_segmentation_array(image_input, nClasses,\n",
        "                           width, height, no_reshape=False, read_image_type=1):\n",
        "    \"\"\" Load segmentation array from input \"\"\"\n",
        "\n",
        "    seg_labels = np.zeros((height, width, nClasses))\n",
        "\n",
        "    if type(image_input) is np.ndarray:\n",
        "        # It is already an array, use it as it is\n",
        "        img = image_input\n",
        "    elif isinstance(image_input, six.string_types):\n",
        "        if not os.path.isfile(image_input):\n",
        "            raise DataLoaderError(\"get_segmentation_array: \"\n",
        "                                  \"path {0} doesn't exist\".format(image_input))\n",
        "        img = cv2.imread(image_input, read_image_type)\n",
        "    else:\n",
        "        raise DataLoaderError(\"get_segmentation_array: \"\n",
        "                              \"Can't process input type {0}\"\n",
        "                              .format(str(type(image_input))))\n",
        "\n",
        "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "    img = img[:, :, 0]\n",
        "\n",
        "    for c in range(nClasses):\n",
        "        seg_labels[:, :, c] = (img == c).astype(int)\n",
        "\n",
        "    if not no_reshape:\n",
        "        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n",
        "\n",
        "    return seg_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6rtwKR_yC6n"
      },
      "outputs": [],
      "source": [
        "class DataLoaderError(Exception):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDGl_8zcyYfo"
      },
      "outputs": [],
      "source": [
        "ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
        "ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\", \".bmp\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e4EYB0krPi7"
      },
      "outputs": [],
      "source": [
        "model = vgg_unet(n_classes=50 ,  input_height=320, input_width=640 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZiD_1BCvK4s"
      },
      "outputs": [],
      "source": [
        "#! wget https://github.com/divamgupta/datasets/releases/download/seg/dataset1.zip && unzip dataset1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b_h15nKvWhh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import sys\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u4fzagPvrkTT",
        "outputId": "eab2cbaa-0575-4178-cb9f-0e5794eab876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying training dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 367/367 [00:03<00:00, 109.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset verified! \n",
            "Epoch 1/5\n",
            "  1/512 [..............................] - ETA: 3:08:54 - loss: 4.3228 - accuracy: 0.0069"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-32112d464319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"/content/dataset1/images_prepped_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/dataset1/annotations_prepped_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcheckpoints_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/tmp/vgg_unet_1\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-83-cf206a3d1241>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_images, train_annotations, input_height, input_width, n_classes, verify_dataset, checkpoints_path, epochs, batch_size, validate, val_images, val_annotations, val_batch_size, auto_resume_checkpoint, load_weights, steps_per_epoch, val_steps_per_epoch, gen_use_multiprocessing, ignore_zero_class, optimizer_name, do_augment, augmentation_name, callbacks, custom_augmentation, other_inputs_paths, preprocessing, read_image_type)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n\u001b[0;32m--> 142\u001b[0;31m                   epochs=epochs, callbacks=callbacks, initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         model.fit(train_gen,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train(\n",
        "    train_images =  \"/content/dataset1/images_prepped_train\",\n",
        "    train_annotations = \"/content/dataset1/annotations_prepped_train\",\n",
        "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=5  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojSWCP-cvghR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqK1l//JHU7NIglS0RvAHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}